{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9fdc0e-e83d-4d78-989b-8d182e1a94ee",
   "metadata": {},
   "source": [
    "This tutorial aims to show the flexibility of modifying, or generating markdown reports from BGCFlow template notebooks.\n",
    "\n",
    "We will go through a simple analysis of filtering results from different genome mining tools and finding our BGC of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc73105b-c32d-4cad-b7c1-57fd26710734",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "This tutorial utilizes the example dataset used in the [BGCFlow manuscript](https://github.com/NBChub/saccharopolyspora_manuscript)\n",
    "\n",
    "To run this tutorial, you will need to finish the `mq_saccharopolyspora` run and build the report.\n",
    "\n",
    "[MQ_Saccharopolyspora Project Configuration](https://github.com/NBChub/bgcflow/tree/dev-0.8.2-notebooks_update4/.examples/mq_saccharopolyspora){:target=\"_blank\" .md-button}\n",
    "\n",
    "Create a new project configuration folder in the `config` folder and copy all the necessary project files there. Then run and build the report as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a125c-810a-46dc-a2a7-127c6919934c",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Finish running BGCFlow\n",
    "bgcflow run\n",
    "\n",
    "# Build the report\n",
    "bgcflow build report\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93142665-f47a-4ef1-8e2b-b43f2da33d3e",
   "metadata": {},
   "source": [
    "Once the run finishes, check the result in the processed directory (`data/processed/mq_saccharopolyspora`), it should generate a folder structure similar to this: \n",
    "```\n",
    ".\n",
    "├── antismash\n",
    "├── bigscape\n",
    "├── bigslice\n",
    "├── data_warehouse\n",
    "├── docs\n",
    "│   ├── antismash.ipynb\n",
    "│   ├── antismash.md\n",
    "│   ├── arts.ipynb\n",
    "│   ├── arts.md\n",
    "│   ├── assets\n",
    "│   ├── bigscape.ipynb\n",
    "│   ├── bigscape.md\n",
    "│   ├── index.md\n",
    "│   ├── query-bigslice.ipynb\n",
    "│   └── query-bigslice.md\n",
    "├── log_changes\n",
    "├── main.py\n",
    "├── metadata\n",
    "├── mkdocs.yml\n",
    "├── overrides\n",
    "├── README.md\n",
    "└── tables\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c971154-b91b-4e41-bf1c-de018c59a50c",
   "metadata": {},
   "source": [
    "BGCFlow contains a starter Jupyter notebook template, generated in the `docs` folder, which are then converted to a `markdown` file, which can be used by `mkdocs` to generate a static HTML site. \n",
    "\n",
    "For more details about customizing the HTML report, see [https://squidfunk.github.io/mkdocs-material/](https://squidfunk.github.io/mkdocs-material/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af7e85-264a-4904-b2f3-a1d4296dae8e",
   "metadata": {},
   "source": [
    "### Default conda environments for the notebooks\n",
    "When you run `bgcflow build report`, you can actually see which conda environments are being used `Snakemake` to generate the report. You can either use this existing environments, or set it up on your own from the recipe.\n",
    "\n",
    "There are two environments that BGCFlow used to make reports, a `Python` and a mix of `R` and `Python` environment:\n",
    "\n",
    "- **Python** - [bgcflow_notes.yaml](https://github.com/NBChub/bgcflow/blob/main/workflow/envs/bgcflow_notes.yaml)\n",
    "- **R** - [r_notebook.yaml](https://github.com/NBChub/bgcflow/blob/main/workflow/envs/r_notebook.yaml)\n",
    "\n",
    "You can install the conda environments using those yaml file by:\n",
    "\n",
    "```bash\n",
    "# use conda or mamba\n",
    "mamba env create -f bgcflow_notes.yaml # or r_notebook.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a02ee5c-d429-4481-8936-08eafb34e9cd",
   "metadata": {},
   "source": [
    "### Adding a new notebook to the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2e0b9f-9a37-4fa7-b282-5086ffce0a6a",
   "metadata": {},
   "source": [
    "To add your own analysis, you can start up Jupyter session using the environments above, and create a new notebook inside the `docs` folder. You can also download this notebook tutorial here:\n",
    "\n",
    "<a href=\"custom_tutorial.ipynb\" download class=\"md-button\">Download Notebook</a>\n",
    "\n",
    "Let's give our notebook the name `custom_tutorial.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c1129f-b5ce-44b9-8473-4b7344962434",
   "metadata": {},
   "source": [
    "## Tutorial 1: Using Tables to Filter and Identify Unique Polyketide BGCs\n",
    "In this notebook, we aim to identify unique polyketide biosynthetic gene clusters (BGCs) that do not have hits in BigFam or MIBiG databases but have been identified in ARTS. This analysis can be used as the first step in the exploratory analysis of discovering potentially novel polyketide BGCs with unique functions. \n",
    "\n",
    "### Setting up libraries and environment variables\n",
    "\n",
    "We will start by use Python and pandas for data manipulation and filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5450a292-0ac7-41a3-8108-d55c56e7c511",
   "metadata": {},
   "source": [
    "First, let's import the necessary Python libraries and define the directory containing our report data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921c042-54a5-4c3b-8c75-3384a07be00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "from itables import to_html_datatable as DT\n",
    "import itables.options as opt\n",
    "\n",
    "opt.css = \"\"\"\n",
    ".itables table td { font-style: italic; font-size: .8em;}\n",
    ".itables table th { font-style: oblique; font-size: .8em; }\n",
    "\"\"\"\n",
    "\n",
    "opt.classes = [\"display\", \"compact\"]\n",
    "opt.lengthMenu = [5, 10, 20, 50, 100, 200, 500]\n",
    "\n",
    "# Define the directory containing the report\n",
    "report_directory = Path(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1398345-ca74-4f9c-b818-ec3c99a554df",
   "metadata": {},
   "source": [
    "Note from the code that the report directory is located one directory above of this notebook (which is located in the `docs` folder)\n",
    "\n",
    "The `metadata` folder records some of the important software versions and also other information of the BGCFlow runs. First, we will fetch the `antiSMASH` version used in the run from the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0795ac-196b-4b85-8604-6e3e4ef63356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dependency versions\n",
    "dependency_versions_file = report_directory / \"metadata/dependency_versions.json\"\n",
    "with open(dependency_versions_file, \"r\") as file:\n",
    "    dependency_versions = json.load(file)\n",
    "\n",
    "# Extract the version of antiSMASH used\n",
    "antismash_version = dependency_versions[\"antismash\"]\n",
    "\n",
    "display(Markdown(f\"> antiSMASH version is: `{antismash_version}`\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6bc56c-d646-4cee-811f-e829afdf9eba",
   "metadata": {},
   "source": [
    "### Setting up input files\n",
    "First, we need to find all the necessary tables or files required for our analysis. Here, we will need the results from antiSMASH, BiG-SCAPE, BiG-FAM query, and also ARTS2.\n",
    "\n",
    "Most of the tables can be found in the `tables` folder, such as the antiSMASH summary region tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ed7cc-d728-4dc9-92a5-515a23f371e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the input files\n",
    "antismash_regions_file = report_directory / f\"tables/df_regions_antismash_{antismash_version}.csv\"\n",
    "display(Markdown(f\">`{antismash_regions_file}`\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf95779d-3d92-459f-9150-ac29afc17943",
   "metadata": {},
   "source": [
    "Some other tables are located in their specific directories, such BiG-SCAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc2a63-43ad-4e42-8789-aec42eadaaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the BIG-SCAPE data\n",
    "bigscape_directory = report_directory / f\"bigscape/for_cytoscape_antismash_{antismash_version}/\"\n",
    "\n",
    "# Find the cluster table file\n",
    "cluster_table_file = [i for i in bigscape_directory.glob(\"*_df_clusters_0.30.csv\")][0]\n",
    "display(Markdown(f\">`{cluster_table_file}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de4f84-abc8-4249-8f14-d1baa42ef283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the query data\n",
    "bigfam_query = report_directory / f\"bigslice/query_as_{antismash_version}/query_network.csv\"\n",
    "display(Markdown(f\">`{bigfam_query}`\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b055c7-8203-428b-998e-94a3c9715b5c",
   "metadata": {},
   "source": [
    "Other tables are created by the Jupyter notebook templates, and usually can be interactively downloaded from the HTML report. By convention, this are stored in the `assets` directory within the `docs` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3027f-d39b-42e2-b235-54f7ce595829",
   "metadata": {},
   "outputs": [],
   "source": [
    "arts_table_file = Path(f\"assets/tables/arts_hits_as{antismash_version}.csv\")\n",
    "display(Markdown(f\">`{arts_table_file}`\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af7bd1f-a21b-4c54-ae43-a294f5289727",
   "metadata": {},
   "source": [
    "### Using pandas and itables to show tables interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b864c292-c33e-4572-b537-a52870d8bdf4",
   "metadata": {},
   "source": [
    "While pandas can show nice summary of a table, it does not do so interactively, and does not render well in the HTML report. We can use [itables](https://mwouts.github.io/itables/quick_start.html) to display our tables as interactive datatables that we can sort, paginate, scroll or filter. To enable this feature in the final report, we are converting the tables to HTML datatables and displaying it with iPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f4fbf-f90d-4ea8-844c-02e1071a1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the input files\n",
    "df_antismash_regions = pd.read_csv(antismash_regions_file)\n",
    "# Correct similarity values and fill null values with 0\n",
    "df_antismash_regions[\"similarity\"] = df_antismash_regions[\"similarity\"].apply(lambda x: 1 if x > 1 else x).fillna(0)\n",
    "\n",
    "df_bigscape = pd.read_csv(cluster_table_file)\n",
    "df_arts_hits = pd.read_csv(arts_table_file)\n",
    "df_bigfam_hits = pd.read_csv(bigfam_query )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e2c5a-0d15-44ea-934b-3940d4b36e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\">`{antismash_regions_file}`\"))\n",
    "display(HTML(DT(df_antismash_regions, scrollX=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1b5d0-8378-4148-b420-760c2942323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\">`{cluster_table_file}`\"))\n",
    "display(HTML(DT(df_bigscape, scrollX=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f00a6-46db-4715-a7aa-a913f7264b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\">`{arts_table_file}`\"))\n",
    "display(HTML(DT(df_arts_hits, scrollX=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aaf536-423b-4ec9-89cc-9c526bb881e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\">`{bigfam_query}`\"))\n",
    "display(HTML(DT(df_bigfam_hits, scrollX=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0115c4d1",
   "metadata": {},
   "source": [
    "Note that these tables are downsampled by default to prevent the Markdown report become heavy. See [https://mwouts.github.io/itables/downsampling.html](https://mwouts.github.io/itables/downsampling.html) for more details. \n",
    "\n",
    "We do not recommend to use the HTML reports to show big tables as it's purpose is to give a quick summary of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d929c27-69c6-4864-b425-a0d53dc0db94",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ffb3b-1764-4d7f-ae6d-092aa169e60b",
   "metadata": {},
   "source": [
    "**BiG-SCAPE filtering**\n",
    "\n",
    "Let's start by looking at the BiG-SCAPE category of unknown PKS. We will create a filtering following this logic:\n",
    "\n",
    "- **Define Classes to Filter By**: We will select all possible PKS categories in BiG-SCAPE and put it in a list named bigscape_class, containing PKSI, PKSother, and PKS-NRP_Hybrids. To see all available bigscape_class, do: `df_bigscape[\"bigscape_class\"].unique()`\n",
    "\n",
    "- **Filter for unknown families**: The column `fam_type_0.30` defines whether the BGCs belongs to a known or unknown GCFs using the cutoff value of 0.3. We will set the string variable family_type to \"unknown_family\", which then used to filter rows based on a column in the DataFrame related to family types.\n",
    "\n",
    "- **Create Masks for Filtering**:\n",
    "\n",
    "    - **mask1**: This is a boolean mask created by checking if the values in the column fam_type_0.30 of df_bigscape are equal to family_type (\"unknown_family\"). This mask is true for rows where the family type is unknown.\n",
    "\n",
    "    - **mask2**: This is another boolean mask created by checking if the values in the column bigscape_class are within the list bigscape_class defined at the start. This mask is true for rows that match any of the specified classes (PKSI, PKSother, PKS-NRP_Hybrids).\n",
    "\n",
    "- **Filter DataFrame**: The DataFrame df_bigscape is filtered using the logical AND (&) of mask1 and mask2. This means only rows where both conditions are true (i.e., the family type is \"unknown_family\" and the bigscape class is one of the specified classes) are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea597d3-0a26-4fa3-9a9a-215a35d8cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigscape_class = ['PKSI', 'PKSother', 'PKS-NRP_Hybrids']\n",
    "family_type = \"unknown_family\"\n",
    "mask1 = df_bigscape[\"fam_type_0.30\"] == family_type\n",
    "mask2 = df_bigscape[\"bigscape_class\"].isin(bigscape_class)\n",
    "df_bigscape_PKS_unknown = df_bigscape[mask1 & mask2]\n",
    "display(HTML(DT(df_bigscape_PKS_unknown, scrollX=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b8f583-e67e-4ec0-9ee9-9f330ac97f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_gcf = len(df_bigscape_PKS_unknown[\"fam_id_0.30\"].unique())\n",
    "\n",
    "text = f\"\"\"We found {df_bigscape.shape[0]} BGC regions in the category of {', '.join(bigscape_class)} which belongs to {family_type.replace('_', ' ')}.\\\n",
    " These BGCs can be grouped into {len(df_bigscape_PKS_unknown[\"fam_id_0.30\"].unique())} GCFs.\"\"\"\n",
    "Markdown(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cde18b-5333-4e47-84ba-9f7e8a469123",
   "metadata": {},
   "source": [
    "**AntiSMASH KnownClusterBlast filtering**\n",
    "\n",
    "We will now look at the KnownClusterBlast similarity score and decide if we need to further filter our search. We will subset the antiSMASH BGC regions table to only contains BGCs identified in the previous step and observe the KnownClusterBlast similarity values. We will narrow down our search by setting up a threshold for the similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d527ba-3b12-427e-b69c-7c5c66613527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the BGC IDs of the unknown families\n",
    "unknown_family_bgcs = df_bigscape_PKS_unknown.bgc_id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8e128-7abf-4d63-8c6d-f6a48842436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_unknown_family = df_antismash_regions.bgc_id.isin(unknown_family_bgcs)\n",
    "columns_to_show = [\"bgc_id\", \"genome_id\", \"product\", \"similarity\", \n",
    "                   \"most_similar_known_cluster_id\", \"most_similar_known_cluster_description\", \"region\", \"contig_edge\", \"region_length\", ]\n",
    "display(HTML(DT(df_antismash_regions[mask_unknown_family].loc[:, columns_to_show], scrollX=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f71be-ac18-4b39-87c7-6edd16f4143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_cutoff = 0.30\n",
    "mask_similarity = df_antismash_regions.similarity < similarity_cutoff\n",
    "text2 = f\"From those **{df_antismash_regions[mask_unknown_family].shape[0]} BGCs**, we actually still have a few BGCs with high similarity based on KnownClusterBlast.\\\n",
    " Let us focus on BGCs with low similarity **(<{similarity_cutoff})**, and now we are left with **{df_antismash_regions[mask_unknown_family & mask_similarity].shape[0]} BGCs**.\"\n",
    "Markdown(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a4398-f468-40d8-b457-d47a7588884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(DT(df_antismash_regions[mask_unknown_family & mask_similarity].loc[:, columns_to_show], scrollX=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec2a7c-49b9-44f0-937e-2d191814781f",
   "metadata": {},
   "source": [
    "**BiG-FAM query filtering**\n",
    "\n",
    "We will also remove all BGCs that has a match to other BGCs in the BiG-FAM database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775d0a8-6734-4557-a47a-fd61b550850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_no_bigfam_hit = ~df_antismash_regions.bgc_id.isin(df_bigfam_hits.bgc_id.unique())\n",
    "display(HTML(DT(df_antismash_regions[mask_unknown_family & mask_similarity & mask_no_bigfam_hit].loc[:, columns_to_show], scrollX=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf52b77-c6fd-4bfc-be61-58244fe46626",
   "metadata": {},
   "source": [
    "**ARTS hits filtering**\n",
    "\n",
    "We will now select only BGCs with close proximity to one of the ARTS2 model. Note that ARTS2 actually have several criteria to prioritise BGCs with possible antibiotic activity, here we just search for all BGCs that has hits to ARTS2 profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e14715-5100-4c06-bc15-41ea67eea782",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arts_hit = df_antismash_regions.bgc_id.isin(df_arts_hits.bgc_id.dropna().unique())\n",
    "df_pks_filtered = df_antismash_regions[mask_unknown_family & mask_similarity & mask_no_bigfam_hit & mask_arts_hit]\n",
    "display(HTML(DT(df_pks_filtered.loc[:, columns_to_show], scrollX=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be994482-8d6c-4c44-98c0-edf01b7b1cf7",
   "metadata": {},
   "source": [
    "### Conclusion for Tutorial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b53ea-ce3e-41e0-ab71-8c6d25cbaf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = f\"We are now left with **{df_pks_filtered.shape[0]} PKS BGCs** of interest which can be further invesigated in-depth.\"\n",
    "Markdown(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072dadd7",
   "metadata": {},
   "source": [
    "This tutorial help us narrow down our search to potentially novel PKS. Nevertheless, an in-depth investigation to the BGC structure and see if it has all the required genes to perform natural product biosynthesis.\n",
    "\n",
    "We also recommend users to try out `Metabase` for a more interactive experience of exploring the datasets. See the how to guide in our [WiKi](https://github.com/NBChub/bgcflow/wiki/04-Building-and-Serving-OLAP-Database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e1a703-90da-4479-904e-1d1166d31fcf",
   "metadata": {},
   "source": [
    "## Tutorial 2: Exploring Integrated Network\n",
    "\n",
    "In the previous tutorial, we have shown how to create a custom notebook, explore, and filter the data using tables generated by BGCFlow.\n",
    "\n",
    "In this notebook, we will do an integrated analysis utilizing networks of knowledge bases from different tools: `BiG-SCAPE`, `antiSMASH KnownClusterBlast`, `BiG-FAM database query`, and `ARTS2`. We will generate a `graphml` file with annotation that can be loaded to Cytoscape and also also attempt to visualize the network in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf126288-c727-460c-86cc-dc8e71f8fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "from itables import to_html_datatable as DT\n",
    "import itables.options as opt\n",
    "\n",
    "opt.css = \"\"\"\n",
    ".itables table td { font-style: italic; font-size: .8em;}\n",
    ".itables table th { font-style: oblique; font-size: .8em; }\n",
    "\"\"\"\n",
    "\n",
    "opt.classes = [\"display\", \"compact\"]\n",
    "opt.lengthMenu = [5, 10, 20, 50, 100, 200, 500]\n",
    "\n",
    "def create_node_trace(G, node_trace_category, color, showtextlabel=False, nodesize=10, nodeopacity=0.8, \n",
    "                      nodesymbol=\"circle\", linewidth=1, linecolor=\"black\", textposition=\"top center\", showlegend=False):\n",
    "    \"\"\"\n",
    "    Create a node trace for a given graph.\n",
    "\n",
    "    Parameters:\n",
    "    G (networkx.Graph): The graph to create the node trace for.\n",
    "    node_trace_category (str): The category of the node trace.\n",
    "    color (str): The color of the nodes.\n",
    "    showtextlabel (bool): Whether to show text labels for the nodes.\n",
    "    nodesize (int): The size of the nodes.\n",
    "    nodeopacity (float): The opacity of the nodes.\n",
    "    nodesymbol (str): The symbol used for the nodes.\n",
    "    linewidth (int): The width of the lines.\n",
    "    linecolor (str): The color of the lines.\n",
    "    textposition (str): The position of the text labels.\n",
    "    showlegend (bool): Whether to show the legend.\n",
    "\n",
    "    Returns:\n",
    "    go.Scatter: The node trace.\n",
    "    \"\"\"\n",
    "    if showtextlabel:\n",
    "        markermode = \"markers+text\"\n",
    "    else:\n",
    "        markermode = \"markers\"\n",
    "    nodes = np.array([node for node in G.nodes() if G.nodes[node][\"node_trace\"] == node_trace_category])\n",
    "    pos = np.array([G.nodes[node]['pos'] for node in nodes.flatten()]).reshape(-1, 2)\n",
    "    xs, ys = pos[:, 0], pos[:, 1]\n",
    "    texts = np.array([G.nodes[node]['text'] for node in nodes if \"text\" in G.nodes[node].keys()])\n",
    "    node_trace = go.Scatter(\n",
    "        x=xs.tolist(),\n",
    "        y=ys.tolist(),\n",
    "        text=texts.tolist(),\n",
    "        textposition=textposition,\n",
    "        mode=markermode,\n",
    "        hoverinfo='text',\n",
    "        name=node_trace_category,\n",
    "        showlegend=showlegend,\n",
    "        marker=dict(\n",
    "            symbol=nodesymbol,\n",
    "            opacity=nodeopacity,\n",
    "            showscale=False,\n",
    "            color=color,\n",
    "            size=nodesize,\n",
    "            line=dict(width=linewidth, color=linecolor)))\n",
    "    return node_trace\n",
    "\n",
    "def create_edge_trace(Graph, name, showlegend=False, color='#888', width=0.5, opacity=0.8, dash=\"solid\"):\n",
    "    \"\"\"\n",
    "    Create an edge trace for a given graph.\n",
    "\n",
    "    Parameters:\n",
    "    Graph (networkx.Graph): The graph to create the edge trace for.\n",
    "    name (str): The name of the edge trace.\n",
    "    showlegend (bool): Whether to show the legend.\n",
    "    color (str): The color of the edges.\n",
    "    width (float): The width of the edges.\n",
    "    opacity (float): The opacity of the edges.\n",
    "    dash (str): The style of the edges.\n",
    "\n",
    "    Returns:\n",
    "    go.Scatter: The edge trace.\n",
    "    \"\"\"\n",
    "    edge_trace = go.Scatter(\n",
    "        x=[],\n",
    "        y=[],\n",
    "        name=name,\n",
    "        opacity=opacity,\n",
    "        line=dict(width=width,color=color, dash=dash),\n",
    "        hoverinfo='none',\n",
    "        mode='lines',\n",
    "        showlegend=showlegend)\n",
    "\n",
    "    edges = np.array([edge for edge in Graph.edges() if G.edges[edge][\"relation_type\"] == name])\n",
    "    pos = np.array([Graph.nodes[e]['pos'] for e in edges.flatten()]).reshape(-1, 2)\n",
    "    xs = np.insert(pos[:, 0], np.arange(2, len(pos[:, 0]), 2), None)\n",
    "    ys = np.insert(pos[:, 1], np.arange(2, len(pos[:, 1]), 2), None)\n",
    "    edge_trace['x'] = xs\n",
    "    edge_trace['y'] = ys\n",
    "\n",
    "    return edge_trace\n",
    "\n",
    "def get_graph_stats(g, graph_name):\n",
    "    \"\"\"\n",
    "    Get statistics for a given graph.\n",
    "\n",
    "    Parameters:\n",
    "    g (networkx.Graph): The graph to get statistics for.\n",
    "    graph_name (str): The name of the graph.\n",
    "\n",
    "    Returns:\n",
    "    str: A string containing the statistics for the graph.\n",
    "    \"\"\"\n",
    "    num_nodes_g = g.number_of_nodes()\n",
    "    num_edges_g = g.number_of_edges()\n",
    "    avg_degree_g = sum(dict(g.degree()).values()) / num_nodes_g\n",
    "    num_bgc_g = sum(1 for _, data in g.nodes(data=True) if data.get('node_trace') == 'BGC')\n",
    "    return f\" - {graph_name} : **{num_nodes_g}** total nodes (**{num_bgc_g}** BGC nodes), **{num_edges_g}** edges, {avg_degree_g:.2f} average degree\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f75f512-2189-4485-b166-05acddaf4d51",
   "metadata": {},
   "source": [
    "### Handling Graphs: Reading, Filtering, and Merging Networks\n",
    "\n",
    "We will start by defining some parameters for filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f710a47-8f6c-4331-b5fa-f9bebcaa4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigscape_cutoff = \"0.30\"\n",
    "bigfam_rank_filter = 1 # only select first hits of bigfam models\n",
    "knownclusterblast_similarity_cutoff = 0.8 # select antismash knownclusterblast hits above 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e0d99c-9b17-44ee-8c28-2b8832adbdeb",
   "metadata": {},
   "source": [
    "And then we will first list all the files that we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c26e47a-0aab-488f-8c12-3adb90b8fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dir = Path(\"../\")\n",
    "dependency_version = report_dir / \"metadata/dependency_versions.json\"\n",
    "with open(dependency_version, \"r\") as file:\n",
    "    dependency_version = json.load(file)\n",
    "\n",
    "antismash_version = dependency_version[\"antismash\"]\n",
    "\n",
    "assets_dir = report_dir / \"docs/assets\"\n",
    "integrated_bigscape_network = assets_dir / f\"data/bigscape_{bigscape_cutoff}_as{antismash_version}.graphml\"\n",
    "bigfam_network = assets_dir / f\"data/query_bigfam_as{antismash_version}_network.json\"\n",
    "arts_hits = assets_dir / f\"tables/arts_hits_as{antismash_version}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd0ceb-e022-4e26-a59d-0bb07184c81a",
   "metadata": {},
   "source": [
    "We will start by reading the input files into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef9ea6-eaba-4195-8504-f0b440bfc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ARTS table\n",
    "df_arts_hits = pd.read_csv(arts_hits)\n",
    "\n",
    "integrated_bigscape_network_graph = nx.read_graphml(integrated_bigscape_network)\n",
    "\n",
    "# Iterate over the nodes of bigscape_network_graph_knownclusterblast\n",
    "for n, data in integrated_bigscape_network_graph.nodes(data=True):\n",
    "    # If node_trace is not in the node's attributes, add it with a default value\n",
    "    if 'node_trace' not in data:\n",
    "        if n.startswith('BGC'):\n",
    "            integrated_bigscape_network_graph.nodes[n]['node_trace'] = 'MIBIG_BiG-SCAPE'\n",
    "        else:\n",
    "            integrated_bigscape_network_graph.nodes[n]['node_trace'] = 'BGC'\n",
    "\n",
    "with open(bigfam_network, \"r\") as f:\n",
    "    graph_data = json.load(f)\n",
    "    bigfam_network_graph = nx.readwrite.json_graph.node_link_graph(graph_data)\n",
    "\n",
    "for n, data in bigfam_network_graph.nodes(data=True):\n",
    "    bigfam_network_graph.nodes[n]['node_trace'] = bigfam_network_graph.nodes[n]['node_type']\n",
    "\n",
    "bigfam_network_graph = nx.relabel_nodes(bigfam_network_graph, lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d603032-a2ca-4924-8d2d-57011b34bda6",
   "metadata": {},
   "source": [
    "And then continue by filtering the networks based on our cutoff definition.\n",
    "\n",
    "In this first part, we will split again the BiG-SCAPE - antiSMASH KnownClusterBlast network into its parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3fe18c-2a59-438e-a0ac-60e44d14d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter edges with relation_type = 'bigscape_similarity'\n",
    "edges_with_bigscape_similarity = [(u, v) for u, v, d in integrated_bigscape_network_graph.edges(data=True) if d['relation_type'] == 'bigscape_similarity']\n",
    "\n",
    "# Filter edges with relation_type = 'knownclusterblast' and similarity above the threshold\n",
    "edges_with_knownclusterblast = [(u, v) for u, v, d in integrated_bigscape_network_graph.edges(data=True) if d['relation_type'] == 'knownclusterblast' and d['similarity'] > knownclusterblast_similarity_cutoff]\n",
    "\n",
    "# Create subgraph\n",
    "bigscape_network_graph_knownclusterblast = integrated_bigscape_network_graph.edge_subgraph(edges_with_knownclusterblast)\n",
    "bigscape_network_graph_bigscape_similarity = integrated_bigscape_network_graph.edge_subgraph(edges_with_bigscape_similarity)\n",
    "\n",
    "# Calculate stats for bigscape_network_graph\n",
    "display(Markdown(get_graph_stats(integrated_bigscape_network_graph, \"integrated_bigscape_network_graph\")))\n",
    "\n",
    "# Calculate stats for bigscape_network_graph_knownclusterblast\n",
    "display(Markdown(get_graph_stats(bigscape_network_graph_knownclusterblast, f\"bigscape_network_graph_knownclusterblast with similarity > {knownclusterblast_similarity_cutoff}\")))\n",
    "\n",
    "# Calculate stats for bigscape_network_graph_bigscape_similarity\n",
    "display(Markdown(get_graph_stats(bigscape_network_graph_bigscape_similarity, \"bigscape_network_graph_bigscape_similarity\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5d24f0-f08f-4f63-a2c7-bb05ee82b422",
   "metadata": {},
   "source": [
    "Next, we will filter the BiG-FAM hits based on the top taxa distribution in the BiG-FAM database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb88c2f-0f54-41ed-92b6-ce86ee13a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigfam_models_stats = pd.DataFrame.from_dict({n:data for n, data in bigfam_network_graph.nodes(data=True) if data[\"node_trace\"] != \"BGC\"}).T\n",
    "\n",
    "deleted_bigfam = []\n",
    "bigfam_taxa_cutoff = 0.3\n",
    "bigfam_filter = bigfam_models_stats[bigfam_models_stats.top_taxa_proportion <= bigfam_taxa_cutoff]\n",
    "for n in bigfam_filter.index:\n",
    "    try:\n",
    "        bigfam_network_graph.remove_node(n)\n",
    "        deleted_bigfam.append(n)  \n",
    "    except nx.NetworkXError as e:\n",
    "        print(e)\n",
    "\n",
    "deleted_bigfam = ', '.join([str(i) for i in deleted_bigfam])\n",
    "display(Markdown(f\"Deleted BigFam models: {deleted_bigfam}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5ac9f-46f1-403f-8dd8-c507e6bc191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter edges with rank = 0\n",
    "edges_with_rank_filtered = [(u, v) for u, v, d in bigfam_network_graph.edges(data=True) if d['rank'] < bigfam_rank_filter]\n",
    "\n",
    "# Create subgraph\n",
    "bigfam_network_graph_filtered = bigfam_network_graph.edge_subgraph(edges_with_rank_filtered)\n",
    "# Iterate over the edges of bigfam_network_graph_filtered\n",
    "for u, v, data in bigfam_network_graph_filtered.edges(data=True):\n",
    "    # Get the relation_type attribute\n",
    "    if \"relation_type\" not in data.keys():\n",
    "        data[\"relation_type\"] = \"bigfam_similarity\"\n",
    "\n",
    "# Calculate stats for bigfam_network_graph\n",
    "display(Markdown(get_graph_stats(bigfam_network_graph, \"bigfam_network_graph\")))\n",
    "\n",
    "# Calculate stats for bigfam_network_graph_filtered\n",
    "display(Markdown(get_graph_stats(bigfam_network_graph_filtered, \"bigfam_network_graph_filtered\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef3f628-8cae-496b-a5b5-e8359fd29043",
   "metadata": {},
   "source": [
    "Once we cleaned up the subgraphs, we then recombine them all again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf23f8-c784-4459-bd65-29807ecfc648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Graphs\n",
    "G = nx.compose(bigscape_network_graph_bigscape_similarity, bigscape_network_graph_knownclusterblast)\n",
    "G = nx.compose(G, bigfam_network_graph_filtered)\n",
    "display(Markdown(get_graph_stats(G, \"integrated_graph\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b326a3e9-42ce-46cc-9e91-37d5fd7e70a4",
   "metadata": {},
   "source": [
    "Finally, we will add the metadata of the ARTS2 hits for prioritization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2eff9e-5562-49c8-b25f-a741074176e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_agg(x):\n",
    "    if x.dtypes == object:\n",
    "        return ', '.join(x)\n",
    "    else:\n",
    "        return x.sum()\n",
    "\n",
    "df_arts_hits_filtered = df_arts_hits[(~df_arts_hits.bgc_id.isna()) & (df_arts_hits.hits > 1)].loc[:, [\"bgc_id\", \"profile\", \"hits\", \"Dup\", \"HGT\", \"Res\", \"BGC\"]]\n",
    "df_arts_hits_filtered = df_arts_hits_filtered.apply(lambda x: x.map(lambda y: y.replace('✔', '1').replace('✖', '0') if isinstance(y, str) else y))\n",
    "df_arts_hits_filtered = df_arts_hits_filtered.apply(lambda x: x.map(lambda y: int(y) if isinstance(y, str) and y.isdigit() else y))\n",
    "df_arts_hits_filtered = df_arts_hits_filtered.groupby(\"bgc_id\").agg(custom_agg)\n",
    "df_arts_hits_filtered = df_arts_hits_filtered.rename(columns={c:f\"ARTS_{c}\" for c in df_arts_hits_filtered.columns})\n",
    "display(HTML(DT(df_arts_hits_filtered.reset_index(), scrollX=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6637671d-7bc4-4b6c-9f28-94819250e6ec",
   "metadata": {},
   "source": [
    "This table are then loaded as the node information for the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed36475-a6fc-47ac-a15d-0bdd116f8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in df_arts_hits_filtered.index:\n",
    "    for c in df_arts_hits_filtered.columns:\n",
    "        G.nodes[n][c] = df_arts_hits_filtered.loc[n, c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088da06a-44a1-454f-b3cf-c2e1236bf44d",
   "metadata": {},
   "source": [
    "Followed by some sanitazion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16289380-8973-4984-a692-ff0abe142d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get self-loops\n",
    "self_loops = nx.selfloop_edges(G)\n",
    "\n",
    "# Check if there are any self-loops\n",
    "if self_loops is not None:\n",
    "    # Remove self-loops\n",
    "    G.remove_edges_from(self_loops)\n",
    "\n",
    "# Iterate over the nodes of the graph, getting the node and its attributes\n",
    "for n, data in G.nodes(data=True):\n",
    "    # Create a list of keys to remove after iterating over the dictionary\n",
    "    keys_to_remove = []\n",
    "    # Iterate over the items in the attributes dictionary\n",
    "    for k, v in data.items():\n",
    "        # Check if the value is not of a type compatible with GraphML\n",
    "        if isinstance(v, list):\n",
    "            data[k] = \", \".join([str(i) for i in v])\n",
    "        elif v is None:\n",
    "            # Add the key to the list of keys to remove\n",
    "            keys_to_remove.append(k)\n",
    "        elif not isinstance(v, (int, float, str, bool, np.int64)):\n",
    "            print(f\"Node {n} has attribute {k} of incompatible type {type(v)}\")\n",
    "    # Remove the keys with None values\n",
    "    for key in keys_to_remove:\n",
    "        del G.nodes[n][key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4dc425-18af-45a8-85bd-24f6e3dd8558",
   "metadata": {},
   "source": [
    "And now, the graph is ready and can be downloaded for display in network visualization tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff205b1a-ad8e-4b26-9021-fb7a60ce9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = Path(f\"assets/integrated_network__bigscape_{bigscape_cutoff}__bigfam_{bigfam_rank_filter}__knownclusterblast_{knownclusterblast_similarity_cutoff}.graphml\")\n",
    "outfile.parent.mkdir(parents=True, exist_ok=True)\n",
    "nx.write_graphml(G, outfile)\n",
    "display(Markdown(f\"[Download Graph]({str(outfile)})\"+'{:target=\"_blank\" .md-button}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100bad9b-13ec-48cd-a785-1e2ca3db0fb4",
   "metadata": {},
   "source": [
    "### Network Visualization\n",
    "\n",
    "While we recommend users to use Network Visualization tools such as Cytoscape or Gephi, we can also attempt to visualize the network in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453f2a2-d2aa-42e6-8c22-a751ac1f3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define layout options\n",
    "options = {\n",
    "    'prog': 'twopi',\n",
    "    #'args': ' '.join(['-Gstart=10', '-Goverlap_scaling=-100'])\n",
    "}\n",
    "\n",
    "# position nodes\n",
    "pos = nx.nx_agraph.pygraphviz_layout(G, **options)#, args='-Goverlap=false -Elen=weight')\n",
    "for n, p in pos.items():\n",
    "    G.nodes[n]['pos'] = p\n",
    "    # set up text display\n",
    "    node_trace = G.nodes[n][\"node_trace\"]\n",
    "    if \"text\" not in G.nodes[n].keys():\n",
    "        text = [n]\n",
    "        for k, v in G.nodes[n].items():\n",
    "            if node_trace == \"BGC\":\n",
    "                if k in [\"genome_id\", \"product\", \"bigscape_class\", \"Organism\"]:\n",
    "                    text.append(f\"{k} : {v}\")\n",
    "        text = \"<br>\".join(text)\n",
    "        G.nodes[n]['text'] = text\n",
    "\n",
    "bigscape_class_labels = set([data['bigscape_class'] for n, data in G.nodes(data=True) if data[\"node_trace\"] == \"BGC\"])\n",
    "bigscape_class_colors = sns.color_palette(\"colorblind\", len(bigscape_class_labels)).as_hex()\n",
    "\n",
    "# define visualization\n",
    "edge_annotation_map = {'bigscape_similarity' : {'color':'black',\n",
    "                                                'width':10\n",
    "                                               },\n",
    "                       'knownclusterblast' : {'color':'grey',\n",
    "                                                'width':0.1\n",
    "                                               },\n",
    "                       'bigfam_similarity' : {'color':'grey',\n",
    "                                                'width':0.1\n",
    "                                               },\n",
    "                      }\n",
    "\n",
    "node_annotation_map = {'MIBIG_BiG-SCAPE' : {'color':'green',\n",
    "                                  'node_symbol' : 'star'},\n",
    "                       'MIBIG_knownclusterblast': {'color':'blue',\n",
    "                                  'node_symbol' : 'star'}, \n",
    "                       \"BGC\" : {'color':'grey',\n",
    "                                'node_symbol' : 'circle'},\n",
    "                       \"BiG-FAM GCFs\" : {'color':'yellow',\n",
    "                                'node_symbol' : 'triangle-up'},\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094e135c-bb08-479f-aa1f-cebde284eb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "node_trace = []\n",
    "edge_trace = []\n",
    "\n",
    "for e in edge_annotation_map.keys():\n",
    "    dash = \"solid\"\n",
    "    if 'knownclusterblast' in e:\n",
    "        dash = \"dot\"\n",
    "    edge_trace = create_edge_trace(G, e, color=edge_annotation_map[e]['color'], dash=dash, showlegend=True)\n",
    "    traces.append(edge_trace)\n",
    "\n",
    "for trace in node_annotation_map.keys():\n",
    "    nodeopacity = 0.5\n",
    "    showtextlabel = False\n",
    "    linecolor = \"black\"\n",
    "    linewidth = 0.5\n",
    "    textposition=\"top left\"\n",
    "    node_size = 8\n",
    "    if trace in bigscape_class_labels:\n",
    "        nodeopacity = 0.8\n",
    "    node_trace = create_node_trace(G, trace, node_annotation_map[trace]['color'], showtextlabel=showtextlabel, \n",
    "                                   nodesymbol=node_annotation_map[trace]['node_symbol'], nodeopacity=nodeopacity, \n",
    "                                   showlegend=True, linecolor=linecolor, linewidth=linewidth, nodesize=node_size,\n",
    "                                   textposition=textposition)\n",
    "    traces.append(node_trace)\n",
    "\n",
    "G_arts = G.copy()\n",
    "for n in G_arts.nodes:\n",
    "    if n in df_arts_hits_filtered.index:\n",
    "        G_arts.nodes[n][\"node_trace\"] = \"ARTS_hits\"\n",
    "\n",
    "nodeopacity = 0.5\n",
    "showtextlabel = False\n",
    "node_symbol = \"circle\"\n",
    "node_color = \"grey\"\n",
    "linecolor = \"red\"\n",
    "linewidth = 1\n",
    "textposition=\"top left\"\n",
    "node_size = 8\n",
    "node_trace = create_node_trace(G_arts, \"ARTS_hits\", node_color, showtextlabel=showtextlabel, \n",
    "                                   nodesymbol=node_symbol, nodeopacity=nodeopacity, \n",
    "                                   showlegend=True, linecolor=linecolor, linewidth=linewidth, nodesize=node_size,\n",
    "                                   textposition=textposition)\n",
    "\n",
    "traces.append(node_trace)\n",
    "\n",
    "fig = go.Figure(data=traces,\n",
    "                layout=go.Layout(\n",
    "                    paper_bgcolor='rgba(0,0,0,0)',\n",
    "                    plot_bgcolor='white',\n",
    "                    showlegend=True,\n",
    "                    hovermode='closest',\n",
    "                    margin=dict(b=20,l=5,r=5,t=40),\n",
    "                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, linecolor='black', mirror=True, linewidth=1),\n",
    "                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, linecolor='black', mirror=True, linewidth=1),\n",
    "                    width=800, height=600)\n",
    "                )\n",
    "\n",
    "outfile = Path(\"assets/figures/integrated_network.html\")\n",
    "outfile.parent.mkdir(parents=True, exist_ok=True)\n",
    "fig.write_html(outfile)\n",
    "\n",
    "display(HTML(filename=str(outfile)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f5552d-f998-4b99-a86b-87b902710c7f",
   "metadata": {},
   "source": [
    "### Adding adjacency edge\n",
    "If you have a high quality (complete) genomes, it might be interesting to see the position of each BGC regions relative to each other in a genome. Unfortunately, there are limited physics-based layout algorithm in python, so it is better to use Cytoscape or Gephi to visualize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce910590-50af-4505-b565-e6c555558963",
   "metadata": {},
   "outputs": [],
   "source": [
    "antismash_table = report_dir / f\"tables/df_regions_antismash_{antismash_version}.csv\"\n",
    "df_antismash = pd.read_csv(antismash_table)\n",
    "\n",
    "# Create a new graph\n",
    "filtered_graph = nx.Graph()\n",
    "\n",
    "# Iterate over the nodes in the original graph\n",
    "for node, data in G.nodes(data=True):\n",
    "    # If the node meets the condition, add it to the new graph\n",
    "    if data.get('node_trace') == 'BGC':\n",
    "        filtered_graph.add_node(node, **data)\n",
    "\n",
    "# Now add only the edges that connect the nodes in the new graph\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if filtered_graph.has_node(u) and filtered_graph.has_node(v):\n",
    "        filtered_graph.add_edge(u, v, **data)\n",
    "\n",
    "for i in df_antismash.index:\n",
    "    current_bgc = df_antismash.loc[i].to_dict()\n",
    "    next_index = i + 1\n",
    "    if next_index < len(df_antismash):\n",
    "        neighbor_bgc = df_antismash.loc[next_index].to_dict()\n",
    "        if current_bgc[\"accession\"] == neighbor_bgc[\"accession\"]:\n",
    "            distance = neighbor_bgc[\"start_pos\"] - current_bgc[\"end_pos\"]\n",
    "            assert distance > 0\n",
    "            if not filtered_graph.has_edge(current_bgc[\"bgc_id\"], neighbor_bgc[\"bgc_id\"]):\n",
    "                filtered_graph.add_edge(current_bgc[\"bgc_id\"], neighbor_bgc[\"bgc_id\"], distance_bp=distance, relation_type=\"genomic_adjacency\")\n",
    "\n",
    "display(Markdown(get_graph_stats(filtered_graph, \"integrated_graph_with_adjacency\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ee577-3e01-4ee7-8b9d-b73420933edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get self-loops\n",
    "self_loops = nx.selfloop_edges(filtered_graph)\n",
    "\n",
    "# Check if there are any self-loops\n",
    "if self_loops is not None:\n",
    "    # Remove self-loops\n",
    "    filtered_graph.remove_edges_from(self_loops)\n",
    "\n",
    "# Iterate over the nodes of the graph, getting the node and its attributes\n",
    "for n, data in filtered_graph.nodes(data=True):\n",
    "    # Create a list of keys to remove after iterating over the dictionary\n",
    "    keys_to_remove = []\n",
    "    # Iterate over the items in the attributes dictionary\n",
    "    for k, v in data.items():\n",
    "        # Check if the value is not of a type compatible with GraphML\n",
    "        if isinstance(v, (list, tuple)):\n",
    "            data[k] = \", \".join([str(i) for i in v])\n",
    "        elif v is None:\n",
    "            # Add the key to the list of keys to remove\n",
    "            keys_to_remove.append(k)\n",
    "        elif not isinstance(v, (int, float, str, bool, np.int64)):\n",
    "            print(f\"Node {n} has attribute {k} of incompatible type {type(v)}\")\n",
    "    # Remove the keys with None values\n",
    "    for key in keys_to_remove:\n",
    "        del filtered_graph.nodes[n][key]\n",
    "\n",
    "outfile = Path(f\"assets/data/bigscape_{bigscape_cutoff}_as{antismash_version}_with_genomic_position.graphml\")\n",
    "outfile.parent.mkdir(parents=True, exist_ok=True)\n",
    "nx.write_graphml(filtered_graph, outfile)\n",
    "display(Markdown(f\"[Download Graph]({str(outfile)})\"+'{:target=\"_blank\" .md-button}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cc0c3e-8b47-47b7-bfbc-31398bcefd1d",
   "metadata": {},
   "source": [
    "## Displaying the notebook in the report\n",
    "To display this notebook in the HTML report, we need to convert this notebook into a Markdown file.\n",
    "\n",
    "First, we need to serve BGCFlow report this command:\n",
    "```bash\n",
    "bgcflow serve --project <project name>\n",
    "```\n",
    "The report will be served locally in [http://localhost:8001/](http://localhost:8001/)\n",
    "\n",
    "Then, to generate the Markdown use NBConvert in the terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60436c2-a27d-41a5-bdef-5c5d1b08feb2",
   "metadata": {},
   "source": [
    "```bash\n",
    "# cd to the docs folder containing this notebook\n",
    "jupyter nbconvert --to markdown \\\n",
    "    --execute \"custom_tutorial.ipynb\" \\\n",
    "    --output \"custom_tutorial.md\" \\\n",
    "    --template \"admonition\" \\\n",
    "    --TemplateExporter.extra_template_basedirs=\"../../../../workflow/notebook/nb_convert\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b870729-94f6-4e29-ab09-01cdf757452d",
   "metadata": {},
   "source": [
    "You can also use the `--no-input` flag if you don't want to show the code cells.\n",
    "\n",
    "Then, add the Markdown file to the `mkdocs.yaml` navigation:\n",
    "\n",
    "```yaml\n",
    "extra:\n",
    "  social:\n",
    "  - icon: fontawesome/brands/twitter\n",
    "    link: https://twitter.com/NPGMgroup\n",
    "  - icon: fontawesome/brands/github\n",
    "    link: https://github.com/NBChub/bgcflow\n",
    "markdown_extensions:\n",
    "- attr_list\n",
    "- admonition\n",
    "- pymdownx.details\n",
    "- pymdownx.superfences\n",
    "nav:\n",
    "- Home: index.md\n",
    "- QC and Data Selection:\n",
    "  - seqfu: seqfu.md\n",
    "  - mash: mash.md\n",
    "  - fastani: fastani.md\n",
    "  - checkm: checkm.md\n",
    "- Functional Annotation:\n",
    "  - prokka-gbk: prokka-gbk.md\n",
    "  - deeptfactor: deeptfactor.md\n",
    "- Genome Mining:\n",
    "  - antismash: antismash.md\n",
    "  - query-bigslice: query-bigslice.md\n",
    "  - bigscape: bigscape.md\n",
    "  - bigslice: bigslice.md\n",
    "  - arts: arts.md\n",
    "  - cblaster-genome: cblaster-genome.md\n",
    "  - cblaster-bgc: cblaster-bgc.md\n",
    "- Phylogenomic Placement:\n",
    "  - automlst-wrapper: automlst-wrapper.md\n",
    "- Comparative Genomics:\n",
    "  - roary: roary.md\n",
    "  - eggnog-roary: eggnog-roary.md\n",
    "- Custom Reports:\n",
    "  - How to Add Custom Analysis to the BGCFlow Report: custom_tutorial.md\n",
    "theme:\n",
    "  icon:\n",
    "    admonition:\n",
    "      note: octicons/tag-16\n",
    "      code: material/code-tags\n",
    "...\n",
    "```\n",
    "\n",
    "Once you updated the `mkdocs.yaml` file, the site will be regenerated to show your newly added report.\n",
    "The report can be opened here [http://localhost:8001/custom_tutorial/](http://localhost:8001/custom_tutorial/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
